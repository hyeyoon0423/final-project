---
title: "Final project"
author: "Hyeyoon Lee, Lianxia Chi"
date: "2024-11-30"
format: html
execute:
  eval: true
  echo: true
---

```{python}
#| echo: false
import pandas as pd
import altair as alt 
from datetime import date
import numpy as np
alt.data_transformers.disable_max_rows() 
import matplotlib.pyplot as plt
import json
import seaborn as sns
import webbrowser
```
1. Data Loading and Cleaning
```{python}

# Define function to clean numeric columns
def convert_numeric_columns(df, cols):
    """
    Convert specified columns to numeric after cleaning unwanted characters.
    """
    for col in cols:
        if col in df.columns:
            # Use raw strings to avoid warnings
            df[col] = (
                df[col]
                .replace(r'[\$,]', '', regex=True)  # Remove dollar signs and commas
                .replace(r'[—]', '0', regex=True)  # Replace dashes with 0
                .replace(' ', '', regex=True)  # Remove non-breaking spaces
            )
            df[col] = pd.to_numeric(df[col], errors='coerce')  # Convert to numeric
    return df

# Define function to standardize column names
def standardize_columns(df, year=None):
    """
    Standardize column names: lowercase, replace spaces with underscores, and add year prefix.
    """
    df.columns = (
        df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('\n', '_')
    )
    # Add year prefix if provided, except for key columns
    if year:
        df = df.rename(columns=lambda x: f"{x}_{year}" if x not in ['company_name', 'industry'] else x)
    return df

# File paths for the datasets
file_2020 = '/Users/hyeyoonsmacbook/Desktop/Github/final-project/data/Public profit and emission database의 사본 - 2020.csv'
file_2021 = '/Users/hyeyoonsmacbook/Desktop/Github/final-project/data/Public profit and emission database의 사본 - 2021.csv'
file_2022 = '/Users/hyeyoonsmacbook/Desktop/Github/final-project/data/Public profit and emission database의 사본 - 2022.csv'

# Load datasets
data_2020 = pd.read_csv(file_2020)
data_2021 = pd.read_csv(file_2021)
data_2022 = pd.read_csv(file_2022)

# Standardize column names
data_2020_cleaned = standardize_columns(data_2020, year=2020)
data_2021_cleaned = standardize_columns(data_2021, year=2021)
data_2022_cleaned = standardize_columns(data_2022, year=2022)

# Convert numeric columns for each dataset
numeric_cols_2020 = ['scope_1_ghg_emissions_tons_co₂e_2020', 'scope_2_emissions__tons_co₂e_2020', 'profit_2020']
numeric_cols_2021 = ['2021_scope_1_emissions_tons_co₂e_2021', '2021_scope_2_emissions_tons_co₂e_2021', '2021_profit_(million_usd)_2021']
numeric_cols_2022 = ['2022_scope_1_emissions_tons_co₂e_2022', '2022_scope_2_emissions_tons_co₂e_2022', '2022_profit_(millions_usd)_2022']

data_2020_cleaned = convert_numeric_columns(data_2020_cleaned, numeric_cols_2020)
data_2021_cleaned = convert_numeric_columns(data_2021_cleaned, numeric_cols_2021)
data_2022_cleaned = convert_numeric_columns(data_2022_cleaned, numeric_cols_2022)

# Combine datasets
merged_data = pd.concat([data_2020_cleaned, data_2021_cleaned, data_2022_cleaned], ignore_index=True)

# Drop duplicates based on 'company_name'
if 'company_name' in merged_data.columns:
    merged_data = merged_data.drop_duplicates(subset=['company_name'], keep='first')
else:
    print("Error: 'company_name' column is missing in the merged dataset.")

# Check and print standardized column names
print("Merged Dataset Columns:", merged_data.columns)

# Check for missing values
missing_values_summary = merged_data.isnull().sum()
print("\nMissing Values Summary:")
print(missing_values_summary)

merged_data.to_csv('/Users/hyeyoonsmacbook/Desktop/Github/final-project/data/merged_data.csv', index=False)
```



2. Plot 

# scope 1 : Direct GHG emissions from owned or controlled sources (e.g., company facilities or vehicles).
# Scope 2: Indirect GHG emissions from the generation of purchased electricity consumed by the company.
# Scope 3: Indirect GHG emissions that occur in the value chain, both upstream and downstream (e.g., supply chain emissions, product use, etc.).


# 2020
```{python}
# Load 2020 dataset
file_2020 = '/Users/hyeyoonsmacbook/Desktop/Github/final-project/data/Public profit and emission database의 사본 - 2020.csv'
data_2020 = pd.read_csv(file_2020)

# Standardize column names for 2020
data_2020_cleaned = standardize_columns(data_2020, year=2020)

# Convert numeric columns for 2020
numeric_cols_2020 = ['scope_1_ghg_emissions_tons_co₂e_2020', 'scope_2_emissions__tons_co₂e_2020', 'profit_2020']
data_2020_cleaned = convert_numeric_columns(data_2020_cleaned, numeric_cols_2020)

# Scatter Plot: Profit vs Scope 1, 2, 3 Emissions (2020)
scatter_plot_2020 = alt.Chart(data_2020_cleaned).mark_circle(size=60).encode(
    x=alt.X('scope_1_ghg_emissions_tons_co₂e_2020:Q', title='Scope 1 GHG Emissions (tons CO2e)'),
    y=alt.Y('profit_2020:Q', title='Profit (Million USD)'),
    color=alt.Color('industry:N', title='Industry'),
    tooltip=['company_name:N', 'industry:N', 'profit_2020:Q', 
             'scope_1_ghg_emissions_tons_co₂e_2020:Q', 'scope_2_emissions__tons_co₂e_2020:Q']
).properties(
    title="Profit vs. Scope 1, 2 Emissions (2020)",
    width=600,
    height=400
)

scatter_plot_2020.show()

# Bar Chart: Total Scope 1, 2 Emissions by Industry (2020)
bar_chart_2020 = alt.Chart(data_2020_cleaned).mark_bar().encode(
    x=alt.X('industry:N', title='Industry', sort='-y'),
    y=alt.Y('sum(scope_1_ghg_emissions_tons_co₂e_2020):Q', title='Total Scope 1 Emissions'),
    color=alt.Color('industry:N', legend=None),
    tooltip=['industry:N', 'sum(scope_1_ghg_emissions_tons_co₂e_2020):Q', 
             'sum(scope_2_emissions__tons_co₂e_2020):Q']
).properties(
    title="Total Scope 1, 2 Emissions by Industry (2020)",
    width=600,
    height=400
)

bar_chart_2020.show()
plt.show()
```

# 2021
```{python}
# Load the 2021 dataset
data_2021 = pd.read_csv('/Users/hyeyoonsmacbook/Desktop/Github/final-project/data/Public profit and emission database의 사본 - 2021.csv')

# Standardize columns for 2021
data_2021_cleaned = standardize_columns(data_2021, year=2021)

# Convert numeric columns for 2021
numeric_cols_2021 = ['2021_scope_1_emissions_tons_co₂e_2021', '2021_scope_2_emissions__tons_co₂e_2021', '2021_scope_3_emissions_tons_co₂e_2021', '2021_profit_(million_usd)_2021']
data_2021_cleaned = convert_numeric_columns(data_2021_cleaned, numeric_cols_2021)

# Scatter Plot: Profit vs Scope 1, 2, 3 Emissions (2021)
scatter_plot_2021_all = alt.Chart(data_2021_cleaned).mark_circle(size=60).encode(
    x=alt.X('2021_scope_1_emissions_tons_co₂e_2021:Q', title='Scope 1 GHG Emissions (tons CO2e)'),
    y=alt.Y('2021_profit_(million_usd)_2021:Q', title='Profit (Million USD)'),
    color=alt.Color('industry:N', title='Industry'),
    tooltip=['company_name:N', 'industry:N', '2021_profit_(million_usd)_2021:Q', 
             '2021_scope_1_emissions_tons_co₂e_2021:Q', '2021_scope_2_emissions__tons_co₂e_2021:Q', 
             '2021_scope_3_emissions_tons_co₂e_2021:Q']
).properties(
    title="Profit vs. Scope 1, 2, 3 Emissions (2021)",
    width=600,
    height=400
)

scatter_plot_2021_all.show()

# Bar Chart: Total Scope 1, 2, 3 Emissions by Industry (2021)
bar_chart_2021_all = alt.Chart(data_2021_cleaned).mark_bar().encode(
    x=alt.X('industry:N', title='Industry', sort='-y'),
    y=alt.Y('sum(2021_scope_1_emissions_tons_co₂e_2021):Q', title='Total Scope 1 Emissions'),
    color=alt.Color('industry:N', legend=None),
    tooltip=['industry:N', 'sum(2021_scope_1_emissions_tons_co₂e_2021):Q', 
             'sum(2021_scope_2_emissions__tons_co₂e_2021):Q', 'sum(2021_scope_3_emissions_tons_co₂e_2021):Q']
).properties(
    title="Total Scope 1, 2, 3 Emissions by Industry (2021)",
    width=600,
    height=400
)

bar_chart_2021_all.show()
plt.show()
```
# 2022
```{python}
# Load the 2022 dataset
data_2022 = pd.read_csv('/Users/hyeyoonsmacbook/Desktop/Github/final-project/data/Public profit and emission database의 사본 - 2022.csv')

# Standardize columns for 2022
data_2022_cleaned = standardize_columns(data_2022, year=2022)

# Convert numeric columns for 2022
numeric_cols_2022 = ['2022_scope_1_emissions_tons_co₂e_2022', '2022_scope_2_emissions__tons_co₂e_2022', '2022_scope_3_emissions_tons_co₂e_2022', '2022_profit_(millions_usd)_2022']
data_2022_cleaned = convert_numeric_columns(data_2022_cleaned, numeric_cols_2022)

# Scatter Plot: Profit vs Scope 1, 2, 3 Emissions (2022)
scatter_plot_2022_all = alt.Chart(data_2022_cleaned).mark_circle(size=60).encode(
    x=alt.X('2022_scope_1_emissions_tons_co₂e_2022:Q', title='Scope 1 GHG Emissions (tons CO2e)'),
    y=alt.Y('2022_profit_(millions_usd)_2022:Q', title='Profit (Million USD)'),
    color=alt.Color('industry:N', title='Industry'),
    tooltip=['company_name:N', 'industry:N', '2022_profit_(millions_usd)_2022:Q', 
             '2022_scope_1_emissions_tons_co₂e_2022:Q', '2022_scope_2_emissions__tons_co₂e_2022:Q', 
             '2022_scope_3_emissions_tons_co₂e_2022:Q']
).properties(
    title="Profit vs. Scope 1, 2, 3 Emissions (2022)",
    width=600,
    height=400
)

scatter_plot_2022_all.show()

# Bar Chart: Total Scope 1, 2, 3 Emissions by Industry (2022)
bar_chart_2022_all = alt.Chart(data_2022_cleaned).mark_bar().encode(
    x=alt.X('industry:N', title='Industry', sort='-y'),
    y=alt.Y('sum(2022_scope_1_emissions_tons_co₂e_2022):Q', title='Total Scope 1 Emissions'),
    color=alt.Color('industry:N', legend=None),
    tooltip=['industry:N', 'sum(2022_scope_1_emissions_tons_co₂e_2022):Q', 
             'sum(2022_scope_2_emissions__tons_co₂e_2022):Q', 'sum(2022_scope_3_emissions_tons_co₂e_2022):Q']
).properties(
    title="Total Scope 1, 2, 3 Emissions by Industry (2022)",
    width=600,
    height=400
)

bar_chart_2022_all.show()
plt.show()
```

## Shiny App: Dynamic Visualization
# The dynamic visualization component of this project is implemented using a Shiny app. 
# The app is located in the `shiny-app` folder and can be launched using the following command:

```{python}
import pandas as pd
import geopandas as gpd
import matplotlib.pyplot as plt
import numpy as np
import requests
import io

# Function to load and prepare data
def load_and_prepare_data():
    # Load data
    file_path = '//Users/joying/Documents/GitHub/final-project/data/merged_data.csv'
    data = pd.read_csv(file_path)

    # Clean company names
    data['company_name'] = data['company_name'].str.strip().str.upper()

    # Map companies to countries (simplified example

    company_to_country = {
   
    "JPMORGAN CHASE": "United States",
    "BERKSHIRE HATHAWAY": "United States",
    "APPLE": "United States",
    "MICROSOFT": "United States",
    "AMAZON": "United States",
    "TESLA": "United States",
    "GOOGLE": "United States",
    "META": "United States",
    "WALMART": "United States",
    "BANK OF AMERICA": "United States",
    "CITIGROUP": "United States",
    "WELLS FARGO": "United States",
    "VERIZON COMMUNICATIONS": "United States",

   
    "ICBC": "China",
    "CHINA CONSTRUCTION BANK": "China",
    "PING AN INSURANCE GROUP": "China",
    "AGRICULTURAL BANK OF CHINA": "China",
    "BANK OF CHINA": "China",
    "TENCENT HOLDINGS": "China",
    "ALIBABA GROUP": "China",
    "SINOPEC": "China",
    "CHINA MOBILE": "China",
    "CHINA MERCHANTS BANK": "China",
    "PETROCHINA": "China",
    "INDUSTRIAL BANK": "China",

 
    "SAUDI ARABIAN OIL COMPANY (SAUDI ARAMCO)": "Saudi Arabia",

   
    "TOYOTA MOTOR": "Japan",
    "SONY": "Japan",
    "HONDA MOTOR": "Japan",
    "MITSUBISHI UFJ FINANCIAL": "Japan",
    "NIPPON TELEGRAPH & TEL": "Japan",

    
    "SAMSUNG ELECTRONICS": "South Korea",
    "HYUNDAI MOTOR": "South Korea",


    "VOLKSWAGEN GROUP": "Germany",
    "BMW GROUP": "Germany",
    "DAIMLER": "Germany",
    "SIEMENS": "Germany",
    "ALLIANZ": "Germany",


    "HSBC HOLDINGS": "United Kingdom",
    "BP": "United Kingdom",
    "SHELL": "United Kingdom",
    "BARCLAYS": "United Kingdom",

   
    "RELIANCE INDUSTRIES": "India",
    "STATE BANK OF INDIA": "India",
    "HDFC BANK": "India",

    
    "BNP PARIBAS": "France",
    "AXA GROUP": "France",
    "TOTALENERGIES": "France",

 
    "NESTLÉ": "Switzerland",
    "ROCHE HOLDING": "Switzerland",
    "NOVARTIS": "Switzerland",

 
    "GAZPROM": "Russia",
    "SBERBANK": "Russia",
    "ROSNEFT": "Russia",

  
    "RBC": "Canada",
    "TD BANK GROUP": "Canada",
    "BANK OF MONTREAL": "Canada",

   
    "PETROBRAS": "Brazil",
    "ITAÚ UNIBANCO HOLDING": "Brazil",

    
    "BHP GROUP": "Australia",
    "COMMONWEALTH BANK": "Australia",

 
    "PHILIPS": "Netherlands",
    "HEINEKEN": "Netherlands",
}

    

    # Map country names
    data['country'] = data['company_name'].map(company_to_country).fillna('UNKNOWN')

    # Calculate total profit and total emissions
    profit_columns = ['profit_2020', '2021_profit_(million_usd)_2021', '2022_profit_(millions_usd)_2022']
    emission_columns = [
        'scope_1_ghg_emissions_tons_co₂e_2020', 'scope_2_emissions__tons_co₂e_2020',
        '2021_scope_1_emissions_tons_co₂e_2021', '2021_scope_2_emissions_tons_co₂e_2021',
        '2022_scope_1_emissions_tons_co₂e_2022', '2022_scope_2_emissions_tons_co₂e_2022'
    ]
    data[profit_columns + emission_columns] = data[profit_columns + emission_columns].fillna(0).apply(pd.to_numeric, errors='coerce')
    data['total_profit'] = data[profit_columns].sum(axis=1)
    data['total_emissions'] = data[emission_columns].sum(axis=1)

    # Group data by country
    country_data = data.groupby('country', as_index=False).agg({'total_profit': 'sum', 'total_emissions': 'sum'})

    # Download world map data
    url = "https://raw.githubusercontent.com/nvkelso/natural-earth-vector/master/geojson/ne_110m_admin_0_countries.geojson"
    response = requests.get(url)
    geojson_data = io.StringIO(response.text)
    world = gpd.read_file(geojson_data)

    # Standardize and fix country names
    world['NAME'] = world['NAME'].str.strip().str.upper().replace({
        'UNITED STATES OF AMERICA': 'UNITED STATES'
    })
    country_data['country'] = country_data['country'].str.strip().str.upper()

    # Merge world map with data
    world = world.merge(country_data, how='left', left_on='NAME', right_on='country')

    # Fill missing values
    world['total_profit'] = world['total_profit'].fillna(0)
    world['total_emissions'] = world['total_emissions'].fillna(0)

    # Log-transform data
    world['log_total_profit'] = world['total_profit'].apply(lambda x: np.log1p(x))
    world['log_total_emissions'] = world['total_emissions'].apply(lambda x: np.log1p(x))

    return data, world

# Load data
data, world_data = load_and_prepare_data()

# Plot the map
def plot_map(data, map_type="Profit"):
    fig, ax = plt.subplots(figsize=(8, 6))
    if map_type == "Profit":
        data.plot(column='log_total_profit', cmap='Blues', legend=True, ax=ax)
        ax.set_title('Log-Transformed Total Profit by Country', fontsize=16)
    elif map_type == "Emissions":
        data.plot(column='log_total_emissions', cmap='Reds', legend=True, ax=ax)
        ax.set_title('Log-Transformed Total Carbon Emissions by Country', fontsize=16)
    else:
        print("Invalid map type. Choose 'Profit' or 'Emissions'.")

    plt.tight_layout()
    plt.show()

# Generate and display the map
plot_map(world_data, map_type="Profit")
plot_map(world_data, map_type="Emissions")
```
# Extra Credit 
```{python}
import nltk
from nltk.sentiment import SentimentIntensityAnalyzer
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
import matplotlib.pyplot as plt
from wordcloud import WordCloud


nltk.download('vader_lexicon')

data = pd.read_csv('/Users/hyeyoonsmacbook/Desktop/Github/final-project/data/merged_data.csv')


data["company_name"] = data["company_name"].fillna("")
data = data.dropna(subset=["country/territory_2020"]) 
country_col = "country/territory_2020"


sia = SentimentIntensityAnalyzer()
data["company_sentiment"] = data["company_name"].apply(lambda x: sia.polarity_scores(str(x))["compound"])


sentiment_summary = data.groupby(country_col)["company_sentiment"].mean().reset_index()


sentiment_summary.sort_values(by="company_sentiment", ascending=False).head(10).plot(
    x=country_col, y="company_sentiment", kind="bar", title="Average Sentiment by Country", legend=False
)
plt.xticks(rotation=45, ha='right')
plt.ylabel("Average Sentiment Score")
plt.xlabel("Country/Territory")
plt.tight_layout()
plt.show()


vectorizer = TfidfVectorizer(max_features=5, stop_words="english")
tfidf_matrix = vectorizer.fit_transform(data["company_name"])
data["keywords"] = [", ".join(vectorizer.get_feature_names_out()) for _ in range(len(data))]


print(data[["company_name", "keywords"]].head())


text = " ".join(data["company_name"])
wordcloud = WordCloud(width=800, height=400, background_color="white").generate(text)


plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis("off")
plt.title("WordCloud of Company Names")
plt.show()
```
```{python}
# Sentiment Analysis Findings
print("### Sentiment Analysis Findings")
print("- Switzerland had the highest average sentiment score (0.04), followed by France and the United States.")
print("- The positive sentiment may be influenced by company names such as 'UBS Group' or 'Credit Suisse,' which might convey stability and reliability in the financial sector.")
print("- On the other hand, countries with lower sentiment scores, such as Australia, may reflect more neutral or less emotionally charged company names.")

# Keyword Analysis Findings
print("\n### Keyword Analysis Findings")
print("- The most frequent keywords included 'Bank,' 'Group,' 'Financial,' and 'China,' highlighting the dominance of banking and financial companies in the dataset.")
print("- The prominence of 'China' reflects the significant presence of Chinese corporations, such as ICBC and China Construction Bank, in the global market.")
print("- Less frequent keywords, like 'Energy' and 'Technology,' suggest that other industries, while present, are less dominant in this dataset.")

# Limitations
print("\n### Limitations")
print("- Company names alone may not carry significant emotional connotations, leading to many neutral sentiment scores.")
print("- The keyword extraction is limited to short company names, which may not provide sufficient context for deeper insights.")
print("- Additional text data, such as company descriptions or news articles, would enhance the analysis.")
```


